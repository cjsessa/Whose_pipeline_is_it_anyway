{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from config import api_key\n",
    "from config import api_id\n",
    "from config import api_key2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating random list for MSAs\n",
    "Keith wrote the code to generate the random list from the top polluting MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Cincinnati-Wilmington-Maysville, OH-KY-IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cleveland-Akron-Canton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fresno-Madera-Hanford, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Houston-The Woodlands, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Indianapolis-Carmel-Muncie, IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Philadelphia-Reading-Camden, PA-NJ-DE-MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Phoenix-Mesa, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Sacramento-Roseville, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Shreveport-Bossier City-Minden, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSA\n",
       "0   Cincinnati-Wilmington-Maysville, OH-KY-IN\n",
       "1                  Cleveland-Akron-Canton, OH\n",
       "2                   Fresno-Madera-Hanford, CA\n",
       "3                   Houston-The Woodlands, TX\n",
       "4              Indianapolis-Carmel-Muncie, IN\n",
       "5    Philadelphia-Reading-Camden, PA-NJ-DE-MD\n",
       "6                            Phoenix-Mesa, AZ\n",
       "7                    Sacramento-Roseville, CA\n",
       "8          Shreveport-Bossier City-Minden, LA"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data to load\n",
    "f = \"../data/msa.csv\"\n",
    "\n",
    "# Count the lines\n",
    "num_lines = sum(1 for l in open(f))\n",
    "\n",
    "# Sample size - retrieving header and 5 MSA's\n",
    "size = 10\n",
    "\n",
    "# The row indices to skip - make sure 0 is not included to keep the header\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
    "\n",
    "# Read the data\n",
    "msa = pd.read_csv(f, skiprows=skip_idx)\n",
    "\n",
    "# Display the sample\n",
    "msa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Striping Leading/Trailing Spaces for Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA</th>\n",
       "      <th>MSA1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Cincinnati-Wilmington-Maysville, OH-KY-IN</td>\n",
       "      <td>Cincinnati-Wilmington-Maysville, OH-KY-IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cleveland-Akron-Canton, OH</td>\n",
       "      <td>Cleveland-Akron-Canton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Fresno-Madera-Hanford, CA</td>\n",
       "      <td>Fresno-Madera-Hanford, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Houston-The Woodlands, TX</td>\n",
       "      <td>Houston-The Woodlands, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Indianapolis-Carmel-Muncie, IN</td>\n",
       "      <td>Indianapolis-Carmel-Muncie, IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Philadelphia-Reading-Camden, PA-NJ-DE-MD</td>\n",
       "      <td>Philadelphia-Reading-Camden, PA-NJ-DE-MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Phoenix-Mesa, AZ</td>\n",
       "      <td>Phoenix-Mesa, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Sacramento-Roseville, CA</td>\n",
       "      <td>Sacramento-Roseville, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Shreveport-Bossier City-Minden, LA</td>\n",
       "      <td>Shreveport-Bossier City-Minden, LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSA  \\\n",
       "0   Cincinnati-Wilmington-Maysville, OH-KY-IN   \n",
       "1                  Cleveland-Akron-Canton, OH   \n",
       "2                   Fresno-Madera-Hanford, CA   \n",
       "3                   Houston-The Woodlands, TX   \n",
       "4              Indianapolis-Carmel-Muncie, IN   \n",
       "5    Philadelphia-Reading-Camden, PA-NJ-DE-MD   \n",
       "6                            Phoenix-Mesa, AZ   \n",
       "7                    Sacramento-Roseville, CA   \n",
       "8          Shreveport-Bossier City-Minden, LA   \n",
       "\n",
       "                                        MSA1  \n",
       "0  Cincinnati-Wilmington-Maysville, OH-KY-IN  \n",
       "1                 Cleveland-Akron-Canton, OH  \n",
       "2                  Fresno-Madera-Hanford, CA  \n",
       "3                  Houston-The Woodlands, TX  \n",
       "4             Indianapolis-Carmel-Muncie, IN  \n",
       "5   Philadelphia-Reading-Camden, PA-NJ-DE-MD  \n",
       "6                           Phoenix-Mesa, AZ  \n",
       "7                   Sacramento-Roseville, CA  \n",
       "8         Shreveport-Bossier City-Minden, LA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa['MSA1']=msa['MSA'].str.strip()\n",
    "msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(len(msa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in MSA Crosswalk info for MSA codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBSA Code</th>\n",
       "      <th>MSA1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1503</td>\n",
       "      <td>41400</td>\n",
       "      <td>Youngstown-Warren, OH-PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1893</td>\n",
       "      <td>49660</td>\n",
       "      <td>Youngstown-Warren, OH-PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1865</td>\n",
       "      <td>48700</td>\n",
       "      <td>Williamsport-Lock Haven, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>30820</td>\n",
       "      <td>Williamsport-Lock Haven, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>48620</td>\n",
       "      <td>Wichita-Arkansas City-Winfield, KS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CBSA Code                                MSA1\n",
       "1503     41400            Youngstown-Warren, OH-PA\n",
       "1893     49660            Youngstown-Warren, OH-PA\n",
       "1865     48700         Williamsport-Lock Haven, PA\n",
       "974      30820         Williamsport-Lock Haven, PA\n",
       "1860     48620  Wichita-Arkansas City-Winfield, KS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"../data/msa_crosswalk.csv\"\n",
    "crosswalk = pd.read_csv(file)\n",
    "crosswalk1 = crosswalk[['CBSA Code','CSA Title']].sort_values('CSA Title',ascending = False).rename(columns = {'CSA Title':'MSA1'}).dropna().drop_duplicates()\n",
    "crosswalk1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining MSA Crosswalk to Top MSAs to get the CBSA Codes needed for API Pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CBSA Code                                      MSA1  \\\n",
      "0     40900                  Sacramento-Roseville, CA   \n",
      "1     46020                  Sacramento-Roseville, CA   \n",
      "2     49700                  Sacramento-Roseville, CA   \n",
      "3     37980  Philadelphia-Reading-Camden, PA-NJ-DE-MD   \n",
      "4     36140  Philadelphia-Reading-Camden, PA-NJ-DE-MD   \n",
      "\n",
      "                                         MSA  \n",
      "0                   Sacramento-Roseville, CA  \n",
      "1                   Sacramento-Roseville, CA  \n",
      "2                   Sacramento-Roseville, CA  \n",
      "3   Philadelphia-Reading-Camden, PA-NJ-DE-MD  \n",
      "4   Philadelphia-Reading-Camden, PA-NJ-DE-MD  \n",
      "-----------------------------------------------------------------------\n",
      "There are multiple CBSA Codes per MSA, there were 9 codes before join and  32 CBSA codes after the join.\n"
     ]
    }
   ],
   "source": [
    "msa_codes = pd.merge(crosswalk1,msa,\n",
    "                how = 'inner',\n",
    "                on = 'MSA1')\n",
    "\n",
    "print(msa_codes.head())\n",
    "print('-----------------------------------------------------------------------')\n",
    "print(\"There are multiple CBSA Codes per MSA, there were \" + str(len(msa)) +\" codes before join and  \"+ str(len(msa_codes)) +\" CBSA codes after the join.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Call - Pollution Part 1\n",
    "using a for loop to loop through three years work of PM2.5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response_sample = []\n",
    "start = [\"20150101\",\"20140101\",\"20130101\"]\n",
    "end = [\"20151231\",\"20141231\",\"20131231\"]\n",
    "codes = msa_codes['CBSA Code']\n",
    "\n",
    "\n",
    "for index in range(len(start)):\n",
    "    for each_msa in codes:\n",
    "        url = f\"https://aqs.epa.gov/data/api/sampleData/byCBSA?email={api_id}&key={api_key}&param=88101&bdate={start[index]}&edate={end[index]}&cbsa={each_msa}\"\n",
    "        response_sample.append(requests.get(url).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling Data and putting in list\n",
    "There are two loops, the first loop is through the 33 different MSAs. Unfortunately the EPA does not always sample every 3 dyas like their website says. This leads to certain sampling sites having different lengths of samples. The second loop goes from 0 to the length of the number of samples they do have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>site</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-11-14</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-11-02</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time        date cbsa_code  site  sample\n",
       "0  00:00  2015-12-20     40900  0006     5.7\n",
       "1  00:00  2015-12-08     40900  0006     9.5\n",
       "2  00:00  2015-11-26     40900  0006     7.3\n",
       "3  00:00  2015-11-14     40900  0006    16.9\n",
       "4  00:00  2015-11-02     40900  0006     2.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = []\n",
    "date = []\n",
    "cbsa_code = []\n",
    "site = []\n",
    "sample = []\n",
    "\n",
    "\n",
    "for x in range(len(response_sample)):\n",
    "# for x in range(0,32):\n",
    "    for y in range(0,response_sample[x]['Header'][0]['rows']):\n",
    "        time.append(response_sample[x]['Data'][y]['time_local'])\n",
    "        date.append(response_sample[x]['Data'][y]['date_local'])\n",
    "        cbsa_code.append(response_sample[x]['Data'][y]['cbsa_code'])\n",
    "        site.append(response_sample[x]['Data'][y]['site_number'])\n",
    "        sample.append(response_sample[x]['Data'][y]['sample_measurement'])\n",
    "\n",
    "columns = ['time','date','cbsa_code','site','sample']\n",
    "df_sample = pd.DataFrame(data = list(zip(time,date,cbsa_code,site,sample)), columns = columns)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting date to DateTime\n",
    "needed to group by month which is format that Oil Data is in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    time       date cbsa_code  site  sample\n",
      "0  00:00 2015-12-20     40900  0006     5.7\n",
      "---------------------------------------------------------\n",
      "There are 646104 rows of PM2.5 data\n"
     ]
    }
   ],
   "source": [
    "df_sample['date'] = pd.to_datetime(df_sample.date,format = '%Y-%m')\n",
    "print(df_sample.head(1))\n",
    "print('---------------------------------------------------------')\n",
    "print(\"There are \"+ str(len(df_sample)) +\" rows of PM2.5 data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>site</th>\n",
       "      <th>sample</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>40900</td>\n",
       "      <td>0006</td>\n",
       "      <td>5.7</td>\n",
       "      <td>12-2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time       date cbsa_code  site  sample month_year\n",
       "0  00:00 2015-12-20     40900  0006     5.7    12-2015"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['month_year'] = df_sample['date'].dt.strftime('%m-%Y')\n",
    "df_sample.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting sample to float to be used for regression/analysis later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample= df_sample.astype({'sample': float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Hourly Data by day & Merging\n",
    "PM2.5 data is organized by hour, but we need it on a daily level so it can map in with the AQI levels. First we do a groupby to get daily levels, then we need to remerge with the original data to get the categorical data back in (county, site, lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month_year cbsa_code  site    sample\n",
      "2508    12-2015     49700  0003  9.771429\n",
      "2453    12-2015     17140  3002  6.790000\n",
      "2456    12-2015     17460  0034  8.100000\n",
      "-----------------------------------------\n",
      "There are 2509 rows after grouping\n"
     ]
    }
   ],
   "source": [
    "df_sample1 = df_sample[['site','sample','month_year','cbsa_code']].groupby(['month_year','cbsa_code','site']).mean().reset_index().sort_values('month_year',ascending = False)\n",
    "df_sample1.head()\n",
    "len(df_sample1)\n",
    "print(df_sample1.head(3))\n",
    "print('-----------------------------------------')\n",
    "print('There are '+ str(len(df_sample1)) + ' rows after grouping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same process for PM2.5 now for AQI\n",
    "AQI = Air Quality Index\n",
    "This is not done every day but every 1 - 3 days depending on how the EPA decided to track it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_daily = []\n",
    "start = [\"20150101\",\"20140101\",\"20130101\"]\n",
    "end = [\"20151231\",\"2014231\",\"20131231\"]\n",
    "codes = msa_codes['CBSA Code']\n",
    "\n",
    "for index in range(len(start)):\n",
    "    for each_msa in codes:\n",
    "        url = f\"https://aqs.epa.gov/data/api/dailyData/byCBSA?email={api_id}&key={api_key}&param=88101&bdate={start[index]}&edate={end[index]}&cbsa={each_msa}\"\n",
    "        response_daily.append(requests.get(url).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-f636a8d62402>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_daily\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresponse_daily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Header'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rows'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_daily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date_local'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_daily\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aqi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rows'"
     ]
    }
   ],
   "source": [
    "date = []\n",
    "cbsa_code = []\n",
    "site = []\n",
    "aqi = []\n",
    "\n",
    "\n",
    "for x in range(len(response_daily)):\n",
    "    for y in range(0,response_daily[x]['Header'][0]['rows']):\n",
    "        date.append(response_daily[x]['Data'][y]['date_local'])\n",
    "        aqi.append(response_daily[x]['Data'][y]['aqi'])\n",
    "        cbsa_code.append(response_daily[x]['Data'][y]['cbsa_code'])\n",
    "        site.append(response_daily[x]['Data'][y]['site_number'])\n",
    "\n",
    "        \n",
    "columns = ['date','aqi','cbsa_code','site']\n",
    "df_daily = pd.DataFrame(data = list(zip(date,aqi,cbsa_code,site)), columns = columns).drop_duplicates().dropna()\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_daily.head())\n",
    "print('---------------------------------------------------------')\n",
    "print('There are '+ str(len(df_daily)) + ' rows from the API pull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['date'] = pd.to_datetime(df_daily.date,format = '%Y-%m')\n",
    "df_daily.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['month_year'] = df_daily['date'].dt.strftime('%m-%Y')\n",
    "df_daily.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily1 = df_daily[['site','aqi','month_year','cbsa_code']].groupby(['month_year','cbsa_code','site']).mean().reset_index().sort_values('month_year',ascending = False)\n",
    "df_daily1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Call Census Data\n",
    "pulling on 5 polluted state/counties from random selection of the top 20 highest polluted counties in the US\n",
    "\n",
    "pulling sectors for mining/quarring, utilities, construction, manufactoring, & wholesale trade\n",
    "\n",
    "https://classcodes.com/naics-2-digit-sector-codes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_survey = ['2017','2015','2014']\n",
    "year_actual = ['2015','2014','2013']\n",
    "variables_interest = ['NAICS2012_TTL,EMP,ESTAB']\n",
    "sectors = [\"31-33\",\"21\",\"22\",\"42\",\"48-49\"]\n",
    "# sectors =[\"31-33\"]\n",
    "codes = msa_codes['CBSA Code']\n",
    "response_census = []\n",
    "year_date = []\n",
    "\n",
    "\n",
    "for index in range(len(year)):\n",
    "    for each_msa in codes:\n",
    "        try:\n",
    "            base_url = f\"https://api.census.gov/data/{year_survey[index]}/cbp?get={variables_interest[0]}&NAICS2012={sectors[0]}&NAICS2012={sectors[1]}&NAICS2012={sectors[2]}&NAICS2012={sectors[3]}&NAICS2012={sectors[4]}&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:{each_msa}&key={api_key2}\"\n",
    "            response_census.append(requests.get(base_url).json())\n",
    "            year_date.append(year_actual[index])\n",
    "        except:\n",
    "            print(f'MSA {each_msa} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics2012_ttl = []\n",
    "cbsa_code = []\n",
    "emp = []\n",
    "estab = []\n",
    "sector = []\n",
    "date = []\n",
    "\n",
    "for x in range(len(response_census)):\n",
    "    for y in range(1,5):\n",
    "        sector.append(response_census[x][y][0])\n",
    "        cbsa_code.append(response_census[x][y][4])\n",
    "        emp.append(response_census[x][y][1])\n",
    "        estab.append(response_census[x][y][2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Census Dataset from Pulled Data\n",
    "dropping first index as it is the column heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sector','cbsa_code','emp','estab','year']\n",
    "census = pd.DataFrame(data = list(zip(sector,cbsa_code,emp,estab,year_date)), columns = columns)\n",
    "census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dummy Variables for Categorical Data of Industries and CBSA Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(census['sector'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.get_dummies(census['cbsa_code'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating Dummy Variables back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_final = pd.concat([df2,df3,census],axis = 1).dropna()\n",
    "census_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_final= census_final.astype({'emp': float,\n",
    "                                  'estab':float})\n",
    "census_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and Cleaning Oil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows before 198\n",
    "file = \"../data/Crude_oil_prices.csv\"\n",
    "oil = pd.read_csv(file)\n",
    "oil_data=oil[(oil['Year']>1984)]\n",
    "oil_data['date'] = pd.to_datetime(oil_data[['Year', 'Month']].assign(DAY=1))\n",
    "oil_data= oil_data.drop(columns=['Free on Board Cost of Crude Oil Imports (Dollars per Barrel)',\n",
    "                                 'Landed Cost of Crude Oil Imports (Dollars per Barrel)',\n",
    "                                 'Refiner Acquisition Cost of Crude Oil, Domestic (Dollars per Barrel)',\n",
    "                                 'Refiner Acquisition Cost of Crude Oil, Imported (Dollars per Barrel)',\n",
    "                                 'Refiner Acquisition Cost of Crude Oil, Composite (Dollars per Barrel)','Month','Year'])\n",
    "oil_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data= oil_data.rename(columns={\"Crude Oil Domestic First Purchase Price (Dollars per Barrel)\":'Crude_Oil_Price'})\n",
    "oil_data= oil_data[['date','Crude_Oil_Price']]\n",
    "index= oil_data[(oil_data['Crude_Oil_Price'] =='Not Available')].index\n",
    "\n",
    "oil_data.drop(index, inplace=True)\n",
    "\n",
    "oil_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data['month_year'] = oil_data['date'].dt.strftime('%m-%Y')\n",
    "oil_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data= oil_data.astype({'Crude_Oil_Price': float})\n",
    "oil_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data1 = oil_data.groupby('month_year').mean().reset_index()\n",
    "oil_data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging in Oil Prices into Census & Pollution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_census = pd.merge(df_sample1, census_final,\n",
    "                      how = 'inner',\n",
    "                      on = 'cbsa_code')\n",
    "pm25_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_census_oil = pd.merge(pm25_census, oil_data1,\n",
    "                          how = 'inner',\n",
    "                          on = 'month_year')\n",
    "pm25_census_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_census = pd.merge(df_daily1,census_final,\n",
    "                     how = 'inner',\n",
    "                     on = 'cbsa_code')\n",
    "aqi_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_census_oil = pd.merge(aqi_census, oil_data1,\n",
    "                          how = 'inner',\n",
    "                          on = 'month_year')\n",
    "aqi_census_oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = aqi_census_oil['aqi']\n",
    "x = aqi_census_oil[['Crude_Oil_Price','Manufacturing','Mining, quarrying, and oil and gas extraction','Transportation and warehousing','Utilities','emp','estab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y,x).fit()\n",
    "predictions = model.predict(x)\n",
    "plt.rc('figure', figsize=(12, 7))\n",
    "plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}, fontproperties = 'monospace')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting AQI, Census, Oil Data to CSV to use in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_census_oil.to_csv('../data/aqi_census_oil1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pm25_census_oil['sample']\n",
    "x1 = pm25_census_oil[['Crude_Oil_Price','Manufacturing','Mining, quarrying, and oil and gas extraction','Transportation and warehousing','Utilities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y1,x1).fit()\n",
    "predictions = model.predict(x1)\n",
    "plt.rc('figure', figsize=(12, 7))\n",
    "plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}, fontproperties = 'monospace')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
